# Table

https://open.kattis.com/problems/table

Table is a problem involving an uncommon algorithm and some non-trivial optimizations. We found some of the following approach during the contest, but missed a few parts necessary for a full solution. You are given a 2000x2000 grid with a number of blocked squares on it. Your goal is to answer a number of queries about how many locations a certain size of rectangle could be placed. Its trivial to do a single such query in time, but we have to do 100k of them. It's pretty clear that we want to compute all the answers and then each query is just a read from a table, but how can we do so quickly?

One way that we could do so is by taking all the point pairs, testing if they contain a block, and adding that rectangle size count if so. This would naively take n^6 time, but we can quickly do some optimizations. The first optimization is to do a walk downwards on our table, and update all the open items with the distance to the next closed item. Now when testing if a rectangle is good, we only need to do a single walk across the bottom edge and check that all of those items are greater than our height. This reduces our time complexity down to n^5. The next step is to note that if a rectangle with given coordinates passes, we know that any rectangle with similar coordinates, but a smaller y2/height will pass as well. We can use a cumulative sum to recover this in an additional O(n^2) time, and this means we have 1 insert for each x1, x2, y1 pair, with a linear search for the appropriate y2. for a total of O(n^4) time. The next step is to note that as we walk our x2 forward, our best y2 will either be the same as the last one, or it will be further restricted by the distance to closed item at this x2. This means that for each x1, y1, we do a linear walk forwards as x2, keeping our min y2 and doing an insert each step, for a total of O(n^3). Finally we're getting close, but this is still far too slow. 

The last optimization is the most complex one, and the hardest to visualize. First let's look at how our x2 walk works; Since we can keep a running min we don't need to re-loop through all the different heights in this row, we just need to check the item that we're on. Is there any way that we could use a similar trick when walking our x1 as well? If we try something like a range tree we still have the problem of needing to query every pair of x1, x2, so that doesn't give us any speed. What if we consider the two cases that we have for each x1, x2 pair and what our result might be after stepping x1. Either x1 was the min before so we now have some greater min on this segment or x1 was not and our min doesn't change for a given x2. It seems like we are interested in the places where the items just outside of our range are a new minimum. For everything in between a given pair of those, the height of our rectangle will be equal to the minimum on that segment, and is guaranteed greater than either edge. How many unique such ranges might there be? For each range, there has to be at least one item in the center that serves as the min, and no item can serve multiple ranges, so it is bounded to size n. Let's just pretend we can easily find such endpoints for each x - how does this give us back the counts? For every x1-x2 range, we want to count all the different sizes of rectangles that can occur inside. For each rectangle of width w, we're going to have 2 spots that we can fit a w-1, 3 spots for a w-2, 4 spots for a w-3, and so on. If we do a cumulative sum once our array becomes all 1s. This represents the x1 starting points. If we do a cumulative sum again, we will add in one for each possible starting point, to each item that is small enough to start there. This is like our x2 ending points or sizes. Great! O(n^2) but wait, there is one problem. What happens when we have items that overlap? Our tall rectangles in the middle might score some of the same small rectangles that span the whole range. To fix this, we will take each rectangle and subtract its intersection with the next tallest rectangle under it, if that exists. Since the rectangle with the smaller height has to cover all the ground the larger rectangle does, it's easy to calculate and remove their intersection. The finishing touch is figuring out how to efficiently get the last and next with smaller heights for each x spot. To do so, we will use the same property that allowed us to calculate and remove the intersections - each rectangle with a smaller height than this rectangle will cover at least as much x range as this will. This means that we can keep a stack of height/start pairs and for each new height we encounter we'll look on the stack for the items that have a higher height that this. Those will be finalized and added to our results table. For items with a smaller height, we can safely put ourselves on top, with a starting index equal to the starting index of the smallest rectangle taller than us, or our own index if there is none. Each item will be added/removed from the stack exactly once, so we are guaranteed O(n) time for each row, and O(n^2) time total. To finish up, we do the cumulative sums described above: 2 in the x direction, 1 in the y direction, and serve the queries.