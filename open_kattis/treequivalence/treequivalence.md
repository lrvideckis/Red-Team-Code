# Treequivalence

https://open.kattis.com/problems/treequivalence

Treequivalence is another one of those problems in which it is incredibly important to read the problem slowly an carefully. The key point is to realize that the subtrees are ordered. This means that if you consider the path around the boundary of a tree, marked by each node it passes, for equivalent trees they will be the same! After this insight, it important to note that the node labels can be repeated, and that must be accounted for - We don't want to consider a rope of a's to be the same as a tree of a's. To solve this part an idea comes to mind involving unique node ids and matching them up, but that leads to a lot of bookkeping, and there is a simpler solution. To keep each node unique within the paths, we will calculate the distance in the path until the next appearance of this node. For leaves this will be path length; For internal nodes this will be the distance around their subtrees, and then the path length - the sum of those distances for the final one. Once we have such an annotated path created for each tree, we will cycle one path around until we test all the cycles, or find a rotation that is the same.

## Time complexity
Creating the trees is done in linear time with a simple recursive parser. The path generation is also linear time, as we can calculate the distances needed in constant time. This leaves the final step, comparing all of the possible rotations. Naively, we will have path length^3, because we need to test each rotation with a linear compare. However, because of the properties of the path, the average case will be significantly better. Essentially each annotated node will add some structure into the tree, so for any tree to have close to worst case performance, it must be remarkably self-similar. One example of such a tree would be a root node A with a massive number of children marked B, and one marked C. Two such trees would compare different immediately on half their rotations, but compare the same up to the first C on the other half. The average expected distance to either C is 1/3 of the path length, and the average expected rotations is 1/2 the path length, so even in this extreme case we would average to (path length ^ 3) / 6.


We can improve this by searching for string 1 inside string 2 duplicated twice. This will reduce our time complexity to N^2, but is not needed.